{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbab1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ca76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 34113\n"
     ]
    }
   ],
   "source": [
    "# Load and combine sentences, then convert to list\n",
    "text_1 = list(gutenberg.sents('carroll-alice.txt'))\n",
    "text_2 = list(gutenberg.sents('austen-emma.txt'))\n",
    "#combined_text = text_1 + text_2\n",
    "# Flatten list of sentences into one long list of tokens\n",
    "tokens = [word.lower() for sent in text_1 for word in sent]\n",
    "print(\"Total tokens:\", len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c5b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean tokens: 27333\n"
     ]
    }
   ],
   "source": [
    "clean_tokens = [tok for tok in tokens if tok.isalpha()]\n",
    "print(\"Clean tokens:\", len(clean_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613df521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2570\n",
      "Encoded length: 27333\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "freq = Counter(clean_tokens)\n",
    "vocab = sorted(freq.keys())\n",
    "\n",
    "word_to_idx = {w: i+1 for i, w in enumerate(vocab)}  # 0 reserved for padding\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "\n",
    "encoded = [word_to_idx[w] for w in clean_tokens]\n",
    "\n",
    "print(\"Vocab size:\", len(word_to_idx) + 1)\n",
    "print(\"Encoded length:\", len(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713ee882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (27327, 6)\n",
      "Targets shape: (27327,)\n"
     ]
    }
   ],
   "source": [
    "seq_len = 6\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(encoded) - seq_len):\n",
    "    inputs.append(encoded[i:i+seq_len])\n",
    "    targets.append(encoded[i+seq_len])\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "targets = np.array(targets)\n",
    "\n",
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138afb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN : ['a', 'daisy', 'chain', 'would', 'be', 'worth']\n",
      "OUT: the\n"
     ]
    }
   ],
   "source": [
    "def inspect(i):\n",
    "    x = inputs[i]\n",
    "    y = targets[i]\n",
    "    print(\"IN :\", [idx_to_word[idx] for idx in x])\n",
    "    print(\"OUT:\", idx_to_word[y])\n",
    "\n",
    "inspect(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a720c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NextWordDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = NextWordDataset(inputs, targets)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c853fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMNextWord(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)               # (B, T, E)\n",
    "        out, _ = self.lstm(x)           # (B, T, H)\n",
    "        out = out[:, -1, :]             # last time step\n",
    "        logits = self.fc(out)           # (B, vocab)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27582b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2570\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_idx) + 1\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef949f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50  Loss: 2617.0893\n",
      "Epoch 2/50  Loss: 2309.8410\n",
      "Epoch 3/50  Loss: 2143.1861\n",
      "Epoch 4/50  Loss: 2010.4620\n",
      "Epoch 5/50  Loss: 1894.5809\n",
      "Epoch 6/50  Loss: 1786.3853\n",
      "Epoch 7/50  Loss: 1684.0673\n",
      "Epoch 8/50  Loss: 1583.5648\n",
      "Epoch 9/50  Loss: 1486.9259\n",
      "Epoch 10/50  Loss: 1392.6430\n",
      "Epoch 11/50  Loss: 1300.9698\n",
      "Epoch 12/50  Loss: 1213.6476\n",
      "Epoch 13/50  Loss: 1130.8572\n",
      "Epoch 14/50  Loss: 1050.8234\n",
      "Epoch 15/50  Loss: 975.1526\n",
      "Epoch 16/50  Loss: 903.2075\n",
      "Epoch 17/50  Loss: 833.9479\n",
      "Epoch 18/50  Loss: 769.4333\n",
      "Epoch 19/50  Loss: 707.3406\n",
      "Epoch 20/50  Loss: 649.6065\n",
      "Epoch 21/50  Loss: 594.5398\n",
      "Epoch 22/50  Loss: 542.4300\n",
      "Epoch 23/50  Loss: 493.6371\n",
      "Epoch 24/50  Loss: 447.7632\n",
      "Epoch 25/50  Loss: 405.2798\n",
      "Epoch 26/50  Loss: 365.2026\n",
      "Epoch 27/50  Loss: 328.1147\n",
      "Epoch 28/50  Loss: 293.4679\n",
      "Epoch 29/50  Loss: 261.9541\n",
      "Epoch 30/50  Loss: 233.0970\n",
      "Epoch 31/50  Loss: 206.5107\n",
      "Epoch 32/50  Loss: 181.7294\n",
      "Epoch 33/50  Loss: 160.5583\n",
      "Epoch 34/50  Loss: 140.3020\n",
      "Epoch 35/50  Loss: 122.2740\n",
      "Epoch 36/50  Loss: 106.7963\n",
      "Epoch 37/50  Loss: 92.9141\n",
      "Epoch 38/50  Loss: 80.7394\n",
      "Epoch 39/50  Loss: 69.5537\n",
      "Epoch 40/50  Loss: 60.4815\n",
      "Epoch 41/50  Loss: 52.3448\n",
      "Epoch 42/50  Loss: 45.7207\n",
      "Epoch 43/50  Loss: 40.2624\n",
      "Epoch 44/50  Loss: 35.5580\n",
      "Epoch 45/50  Loss: 30.6502\n",
      "Epoch 46/50  Loss: 27.5194\n",
      "Epoch 47/50  Loss: 26.9583\n",
      "Epoch 48/50  Loss: 23.7060\n",
      "Epoch 49/50  Loss: 19.7878\n",
      "Epoch 50/50  Loss: 17.3977\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMNextWord(vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}  Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0829cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, seed_words, num_words=20, temperature=1.0):\n",
    "    model.eval()\n",
    "    words = seed_words.lower().split()\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        # Convert last seq_len words to indices\n",
    "        last_words = words[-seq_len:]\n",
    "        encoded = [word_to_idx.get(w, 0) for w in last_words]\n",
    "        x = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            logits = logits / temperature\n",
    "            probs = F.softmax(logits, dim=-1).squeeze()\n",
    "\n",
    "        # Sample\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        next_word = idx_to_word.get(next_idx, \"<unk>\")\n",
    "\n",
    "        words.append(next_word)\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5649464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let s play a game and alice did not be very civil of swimming at school i slates in a nervous tone i m with a telescope i know it s always now with a great many teeth and at\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"let s play a game\", num_words=35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808ae69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
