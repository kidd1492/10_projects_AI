{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b88f1ff",
   "metadata": {},
   "source": [
    "# PyTorch RNN\n",
    "\n",
    "[RNN Doc PyTorch](https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html#rnn)\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- input_size – The number of expected features in the input x\n",
    "- hidden_size – The number of features in the hidden state h\n",
    "\n",
    "- batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) \n",
    "- instead of (seq, batch, feature). \n",
    "\n",
    "Note that this does not apply to hidden or cell states. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774f64d",
   "metadata": {},
   "source": [
    "# Generating a Synthetic Weather Time-Series\n",
    "\n",
    "To train an RNN, we need a sequence with memory. Weather is a natural example: \n",
    "today’s temperature depends on previous days plus some randomness.\n",
    "\n",
    "We generate a simple autoregressive process:\n",
    "\n",
    "`T_t = 0.7 * T_(t-1) + 0.2 * T_(t-2) + Normal(0, 0.5)`\n",
    "\n",
    "This produces a smooth temperature sequence with short-term memory and noise.\n",
    "We will use the first 5 days to predict day 6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "temps = []\n",
    "temps.append(20)   # seed day 0\n",
    "temps.append(21)   # seed day 1\n",
    "\n",
    "for t in range(2, 100):\n",
    "    next_temp = (\n",
    "        0.7 * temps[-1] +\n",
    "        0.2 * temps[-2] +\n",
    "        np.random.normal(0, 0.5)\n",
    "    )\n",
    "    temps.append(next_temp)\n",
    "\n",
    "input_sq = temps[:5]\n",
    "target = temps[5]\n",
    "print(input_sq, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class RNNPredictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=20):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size) \n",
    "        out, h = self.rnn(x)\n",
    "        last_h = out[:, -1, :]   # final hidden state\n",
    "        y_pred = self.fc(last_h)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ced5c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Make the dataset tensor instead of np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, seq_len=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(data[i+seq_len])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = make_dataset(temps, seq_len=5)\n",
    "\n",
    "# reshape for PyTorch: (batch, seq_len, input_size)\n",
    "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430add5",
   "metadata": {},
   "source": [
    "### input: tensor of shape (L, H_in)\n",
    "### hx tensor of shape (D * num_layers, H_out)\n",
    "\n",
    "- L = sequence length\n",
    "- H_in = input size\n",
    "- D = defult **(1)** 2 if bidirectional=True\n",
    "- H_out = hidden size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0c2d5",
   "metadata": {},
   "source": [
    "## Just like before \n",
    "\n",
    "- define the model\n",
    "- define the loss_fn\n",
    "- define the optimizer\n",
    "- write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNPredictor(input_size=1, hidden_size=20)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 300 == 0:\n",
    "        print(f\"epoch {epoch}, loss={loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b58b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor(temps[:5]).unsqueeze(0).unsqueeze(-1)\n",
    "pred = model(test_seq)\n",
    "\n",
    "print(\"Input:\", temps[:5])\n",
    "print(\"Prediction:\", pred.item())\n",
    "print(\"True next value:\", temps[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6ee86",
   "metadata": {},
   "source": [
    "# One To Many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff010a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNotm(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=20):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        out, h = self.rnn(x)\n",
    "        last_h = out[:, -1, :]   # final hidden state\n",
    "        y_pred = self.fc(last_h)\n",
    "        return y_pred\n",
    "    \n",
    "    def generate(self, x0, steps=10):\n",
    "        \"\"\"\n",
    "        x0: (batch, seq_len, input_size) initial sequence\n",
    "        steps: how many future steps to generate\n",
    "        \"\"\"\n",
    "        self.eval()  # generation mode\n",
    "\n",
    "        outputs = []\n",
    "        x = x0\n",
    "        h = None\n",
    "\n",
    "        for _ in range(steps):\n",
    "            out, h = self.rnn(x, h)\n",
    "            last_h = out[:, -1, :]\n",
    "            y = self.fc(last_h)              # next predicted value\n",
    "            outputs.append(y)\n",
    "\n",
    "            # feed prediction back in as next input\n",
    "            x = torch.cat([x[:, 1:, :], y.unsqueeze(1)], dim=1)\n",
    "\n",
    "        return torch.stack(outputs, dim=1)   # (batch, steps, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_otm = RNNotm(input_size=1, hidden_size=20)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_otm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a33e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model...\n",
    "for epoch in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_otm(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# now generate\n",
    "seed = X[0].unsqueeze(0)\n",
    "future = model_otm.generate(seed, steps=10)\n",
    "\n",
    "print(\"seed =\", seed)\n",
    "print(\"future shape =\", future.shape)\n",
    "print(\"future =\", future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e7b26",
   "metadata": {},
   "source": [
    "# seq to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"hello\", \"hola\"),\n",
    "    (\"how are you\", \"cómo estás\"),\n",
    "    (\"i am fine\", \"estoy bien\"),\n",
    "    (\"thank you\", \"gracias\"),\n",
    "    (\"good morning\", \"buenos días\"),\n",
    "    (\"good night\", \"buenas noches\"),\n",
    "    (\"see you later\", \"hasta luego\"),\n",
    "    (\"i love you\", \"te quiero\"),\n",
    "    (\"what is your name\", \"cómo te llamas\"),\n",
    "    (\"my name is john\", \"me llamo john\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    counter = Counter()\n",
    "    for s in sentences:\n",
    "        counter.update(s.split())\n",
    "\n",
    "    vocab = [\"<pad>\", \"<sos>\", \"<eos>\"] + sorted(counter.keys())\n",
    "    stoi = {w:i for i,w in enumerate(vocab)}\n",
    "    itos = {i:w for w,i in stoi.items()}\n",
    "    return vocab, stoi, itos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ae51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences = [e for e, _ in pairs]\n",
    "spa_sentences = [s for _, s in pairs]\n",
    "\n",
    "eng_vocab, eng_stoi, eng_itos = build_vocab(eng_sentences)\n",
    "spa_vocab, spa_stoi, spa_itos = build_vocab(spa_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deccbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence, stoi):\n",
    "    tokens = sentence.split()\n",
    "    ids = [stoi[\"<sos>\"]] + [stoi[t] for t in tokens] + [stoi[\"<eos>\"]]\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d705af",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pairs = [\n",
    "    (encode_sentence(e, eng_stoi), encode_sentence(s, spa_stoi))\n",
    "    for e, s in pairs\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len, pad_idx):\n",
    "    return seq + [pad_idx] * (max_len - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(encoded_pairs):\n",
    "    eng_max = max(len(e) for e, _ in encoded_pairs)\n",
    "    spa_max = max(len(s) for _, s in encoded_pairs)\n",
    "\n",
    "    eng_batch = []\n",
    "    spa_batch = []\n",
    "\n",
    "    for e, s in encoded_pairs:\n",
    "        eng_batch.append(pad_sequence(e, eng_max, eng_stoi[\"<pad>\"]))\n",
    "        spa_batch.append(pad_sequence(s, spa_max, spa_stoi[\"<pad>\"]))\n",
    "\n",
    "    return torch.tensor(eng_batch), torch.tensor(spa_batch)\n",
    "\n",
    "src_batch, tgt_batch = make_batch(encoded_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d17194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, encoded_pairs):\n",
    "        self.data = encoded_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.data[idx]\n",
    "        return torch.tensor(src), torch.tensor(tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    src_max = max(len(s) for s in src_batch)\n",
    "    tgt_max = max(len(t) for t in tgt_batch)\n",
    "\n",
    "    def pad(seq, max_len, pad_idx):\n",
    "        pad_tensor = torch.tensor([pad_idx] * (max_len - len(seq)), dtype=torch.long)\n",
    "        return torch.cat([seq, pad_tensor])\n",
    "\n",
    "    src_padded = torch.stack([pad(s, src_max, eng_stoi[\"<pad>\"]) for s in src_batch])\n",
    "    tgt_padded = torch.stack([pad(t, tgt_max, spa_stoi[\"<pad>\"]) for t in tgt_batch])\n",
    "\n",
    "    return src_padded.long(), tgt_padded.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(encoded_pairs)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed(x)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden  # (1, batch, hidden)\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embed(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        hidden = self.encoder(src)\n",
    "        outputs, _ = self.decoder(tgt[:, :-1], hidden)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "\n",
    "encoder = Encoder(len(eng_vocab), embed_size, hidden_size).to(device)\n",
    "decoder = Decoder(len(spa_vocab), embed_size, hidden_size).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=spa_stoi[\"<pad>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(src, tgt)  # (batch, seq_len-1, vocab)\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt[:, 1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8aaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    model.eval()\n",
    "\n",
    "    # Encode the English sentence\n",
    "    src_ids = encode_sentence(sentence, eng_stoi)\n",
    "    src = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Encode with the encoder\n",
    "    hidden = encoder(src)\n",
    "\n",
    "    # Start decoder with <sos>\n",
    "    tgt_idx = spa_stoi[\"<sos>\"]\n",
    "    tgt = torch.tensor([[tgt_idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    result_tokens = []\n",
    "\n",
    "    for _ in range(20):  # max output length\n",
    "        logits, hidden = decoder(tgt, hidden)\n",
    "\n",
    "        # Get the last predicted token\n",
    "        next_token = logits[:, -1].argmax(dim=-1).item()\n",
    "\n",
    "        if next_token == spa_stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "        result_tokens.append(spa_itos[next_token])\n",
    "\n",
    "        # Feed the predicted token back into the decoder\n",
    "        tgt = torch.tensor([[next_token]], dtype=torch.long).to(device)\n",
    "\n",
    "    return \" \".join(result_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translate(\"hello\"))\n",
    "print(translate(\"i love you\"))\n",
    "print(translate(\"thank you\"))\n",
    "print(translate(\"what is your name\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
