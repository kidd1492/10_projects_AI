{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b6515",
   "metadata": {},
   "source": [
    "Imports:\n",
    "- torch.nn as nn [PyTorch docs :torch.nn ](https://docs.pytorch.org/docs/stable/nn.html)\n",
    "- torch.optim [PyTorch docs](https://docs.pytorch.org/docs/stable/optim.html#module-torch.optim)\n",
    "    - a package implementing various optimization algorithms.\n",
    "\n",
    "Containers :\n",
    "- nn.Module : Base class for all neural network modules.\n",
    "- nn.Sequential() : [pytorch doc :Sequential](https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)\n",
    "\n",
    "Non-Linear Activations :\n",
    "- nn.ReLU\n",
    "- nn.Sigmoid\n",
    "\n",
    "Loss Functions :\n",
    "- nn.BCELoss() : Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:\n",
    "- nn.BCEWithLogitsLoss() : This loss combines a Sigmoid layer and the BCELoss in one single class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09661060",
   "metadata": {},
   "source": [
    "# torch.tensor([])\n",
    "\n",
    "```\n",
    "X = torch.tensor([\n",
    "X = np.array([                      \n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "y = torch.tensor([\n",
    "y = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "], dtype=np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X = torch.tensor([\n",
    "    [0., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 0.],\n",
    "    [1., 1.]\n",
    "])\n",
    "\n",
    "y = torch.tensor([\n",
    "    [0.],\n",
    "    [1.],\n",
    "    [1.],\n",
    "    [0.]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d799166",
   "metadata": {},
   "source": [
    "Since the BCEWithLogitsLoss() has a built in sigmoid layer we can leave the sigmoid out of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORNet_simple(nn.Module):  #nn.Module Base class for all neural network modules\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 3),     # Input → Hidden\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 1),     # Hidden → Output\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "model = XORNet_simple()\n",
    "print(model)\n",
    "print()\n",
    "print(model(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e32584",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()  # stable version of BCE\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # matches your scratch trainer\n",
    "print(optimizer.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08981803",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"name {name} : params: {param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eee601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(X)\n",
    "    preds = torch.sigmoid(logits)\n",
    "\n",
    "    print(\"\\nPredictions:\")\n",
    "    for inp, pred in zip(X, preds):\n",
    "        print(f\"Input: {inp.tolist()} -> Prediction: {pred.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
