{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03339a1f",
   "metadata": {},
   "source": [
    "# Project 5 â€” The Design Matrix & The Structure of Neural Networks\n",
    "\n",
    "**Why This Project Exists**\n",
    "Projects 1â€“4 taught you the operations of machine learning:\n",
    "\n",
    "- dot products\n",
    "- gradients\n",
    "- MSE\n",
    "- crossâ€‘entropy\n",
    "- logistic regression\n",
    "- hidden layers\n",
    "\n",
    "But they didnâ€™t yet reveal the structural object that unifies all of them:\n",
    "\n",
    "### The Design Matrix **ğ‘‹**\n",
    "\n",
    "This project shows:\n",
    "\n",
    "- Why ML always uses a matrix\n",
    "- how OLS is literally a matrix equation\n",
    "- how neural networks generalize it\n",
    "- how batching is just slicing rows of ğ‘‹\n",
    "- how shapes flow through the entire system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d2168",
   "metadata": {},
   "source": [
    "## What Is the Design Matrix?\n",
    "\n",
    "**A design matrix is how machine learning represents data.**\n",
    "\n",
    "Each row = one example = \n",
    "- n = number of examples (rows of X)\n",
    "\n",
    "Each column = one feature\n",
    "- d = number of features (columns of X)\n",
    "\n",
    "So when we say:\n",
    "\n",
    "ğ‘‹\n",
    "âˆˆ\n",
    "ğ‘…\n",
    "ğ‘›\n",
    "Ã—\n",
    "ğ‘‘\n",
    "\n",
    "We mean:\n",
    "\n",
    "- X has n rows (one per data point)\n",
    "- X has d columns (one per feature)\n",
    "\n",
    "![image](mathmatic/matrix_shape.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e87d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]]),\n",
       " (3, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3 samples, 2 features\n",
    "X = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "X, X.shape\n",
    "\n",
    "# this is the simplest possible design matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d652a",
   "metadata": {},
   "source": [
    "## From One Example to Many: Matrix Multiplication\n",
    "\n",
    "Now suppose we want predictions for all n examples at once.\n",
    "\n",
    "Instead of computing:\n",
    "\n",
    "y^(1),y^(2),Y^(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdd84a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = 3.0, 4.0\n",
    "w1, w2 = 2.0, -1.0\n",
    "b = 0.5\n",
    "\n",
    "y_hat_scalar = w1*x1 + w2*x2 + b\n",
    "y_hat_scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0e0d9",
   "metadata": {},
   "source": [
    "## Vector Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfee50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3.0, 4.0])\n",
    "w = np.array([2.0, -1.0])\n",
    "b = 0.5\n",
    "\n",
    "y_hat_vector = w @ x + b\n",
    "y_hat_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3e67f",
   "metadata": {},
   "source": [
    "Matrix Form (All n Examples at Once)\n",
    "Stack all examples into the design matrix:\n",
    "\n",
    "ğ‘¦^ = ğ‘‹ğ‘¤ + ğ‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61f3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [2.5],\n",
       "       [4.5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "w = np.array([[2.0], [-1.0]])  # shape (d,1)\n",
    "b = 0.5\n",
    "\n",
    "y_hat_matrix = X @ w + b\n",
    "y_hat_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4279a6e",
   "metadata": {},
   "source": [
    "### We have already seen this in Logistic Regression\n",
    "\n",
    "The forward pass is:\n",
    "\n",
    "- ğ‘§ = ğ‘‹ğ‘¤ + ğ‘\n",
    "- ğ‘¦^ = ğœ(ğ‘§)\n",
    "\n",
    "\n",
    "Same structure â€” just with a sigmoid on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c3c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62245933],\n",
       "       [0.92414182],\n",
       "       [0.98901306]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = X @ w + b\n",
    "y_hat_logistic = sigmoid(z)\n",
    "y_hat_logistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a673c4e",
   "metadata": {},
   "source": [
    "### â€¦we can finally show the big idea:\n",
    "\n",
    "## A neural network layer is just a generalization of\n",
    "\n",
    "ğ‘‹ğ‘¤ + ğ‘\n",
    "\n",
    "Instead of one output, we compute h outputs:\n",
    "\n",
    "ğ‘‹ğ‘Š + ğ‘\n",
    "\n",
    "Where:\n",
    "\n",
    "ğ‘Š is (ğ‘‘ Ã— â„)\n",
    "\n",
    "output is \n",
    "\n",
    "(ğ‘› Ã— â„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e0cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.1,  2.8, -2.2],\n",
       "        [ 5.1,  4.8, -4.2],\n",
       "        [ 8.1,  6.8, -6.2]]),\n",
       " (3, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X: (n=3 samples, d=2 features)\n",
    "X = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "])\n",
    "\n",
    "# W: (d=2 features, h=3 outputs)\n",
    "W = np.array([\n",
    "    [1.0, -1.0,  0.5],\n",
    "    [0.5,  2.0, -1.5]\n",
    "])\n",
    "\n",
    "b = np.array([0.1, -0.2, 0.3])\n",
    "\n",
    "Z = X @ W + b\n",
    "Z, Z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3f1864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89090318, 0.94267582, 0.09975049],\n",
       "       [0.9939402 , 0.99183743, 0.01477403],\n",
       "       [0.99969655, 0.99888746, 0.00202532]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an activation \n",
    "A = sigmoid(Z)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6434e8",
   "metadata": {},
   "source": [
    "## Building a Real Design Matrix (US House Prices Dataset)\n",
    "**Now we connect everything to a real dataset.**\n",
    "\n",
    "I have a kaggle not book of this that uses US housing prices dataset.\n",
    "Weâ€™ll build a design matrix from these.\n",
    "\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62693100",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO create a file to create a dataset for the github repo version\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"house_prices.csv\")\n",
    "df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "features = [\"sqft_living\", \"bedrooms\", \"bathrooms\"]\n",
    "target = \"price\"\n",
    "\n",
    "X = df[features].values  # shape (n, d)\n",
    "y = df[target].values.reshape(-1, 1)\n",
    "X.shape, y.shape\n",
    "\n",
    "# add a bias column for ols\n",
    "X_ols = np.column_stack([np.ones(len(X)), X])\n",
    "X_ols.shape\n",
    "\n",
    "#ols solution\n",
    "beta = np.linalg.inv(X_ols.T @ X_ols) @ (X_ols.T @ y)\n",
    "beta\n",
    "\n",
    "# predictions\n",
    "y_hat = X_ols @ beta\n",
    "y_hat[:5]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fe2ba",
   "metadata": {},
   "source": [
    "## This is the exact same structure as:\n",
    "\n",
    "- linear regression\n",
    "- logistic regression\n",
    "- neural network layers\n",
    "- Everything is built on:\n",
    "\n",
    "ğ‘‹ğ‘Š + ğ‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd210f50",
   "metadata": {},
   "source": [
    "# Final Summary: The Unifying Structure\n",
    "**Youâ€™ve now seen the entire descent:**\n",
    "\n",
    "- Singleâ€‘input linear regression\n",
    "- Multiâ€‘input dot product\n",
    "- Matrix form (Xw + b)\n",
    "- Logistic regression (sigmoid on top)\n",
    "- Neural network layer (XW + b)\n",
    "\n",
    "Real design matrix from real data\n",
    "\n",
    "**The entire field of supervised learning is built from:**\n",
    "\n",
    "- Linear transformation ğ‘‹ğ‘Š + ğ‘\n",
    "\n",
    "- Nonlinearity ğ‘“(â‹…)\n",
    "\n",
    "**Stack these two ideas and you get:**\n",
    "\n",
    "- regression\n",
    "- classification\n",
    "- deep neural networks\n",
    "- transformers\n",
    "- everything\n",
    "\n",
    "This project completes your firstâ€‘principles foundation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
