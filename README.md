# 10_projects_AI
10 projects to understand AI neural networks
AI Learning Roadmap

**Section 1: Foundations (Math, Regression, Classification, XOR)**

These four projects build the mental model of linear algebra â†’ optimization â†’ nonlinearity.


1. Singleâ€‘Feature Linear Regression

- r, RÂ², OLS
- Geometry of projection
- MSE, gradients, updates

2. Multiâ€‘Feature Regression

- Vectorized dot products
- Weight vector as a direction in feature space
- Plane instead of line
- Residual vectors

3. Binary Classification

- Logistic regression
- Sigmoid
- Crossâ€‘entropy
- Decision boundary geometry

4. Neural Network for XOR

- Hidden layer
- Activation functions
- Geometry of separating nonâ€‘linearly separable data

5. The Design Matrix **ğ‘‹** Neural network layers

- Why ML always uses a matrix
- how OLS is literally a matrix equation
- how neural networks generalize it
- how batching is just slicing rows of ğ‘‹
- how shapes flow through the entire system


**Section 2: Sequence Models (RNN â†’ LSTM â†’ Protoâ€‘LLM)**

6. Build a Neural Network Class From Scratch

- A Layer class
- A NeuralNetwork class
- Forward pass
- Backprop
- Training loop
- Loss functions
- Activation functions

7. Simple RNN: Next Character Predictor

- Recurrence
- Exploding/vanishing gradients
- How memory works

8. LSTM: Better Sequence Memory

- Gates
- Cell state
- Why LSTMs solved longâ€‘range dependencies

9. Translation Miniâ€‘Model (English â†’ Spanish)

- Sequenceâ€‘toâ€‘sequence
- Encoder/decoder
- Attention 


**Neural Networks Simple Math**